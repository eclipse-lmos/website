"use strict";(self.webpackChunklmos_website=self.webpackChunklmos_website||[]).push([[687],{9:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"lmos_protocol/agent_description","title":"Agent Description Format","description":"Standardized agent metadata format.","source":"@site/docs/lmos_protocol/04-agent_description.md","sourceDirName":"lmos_protocol","slug":"/lmos_protocol/agent_description","permalink":"/lmos/docs/lmos_protocol/agent_description","draft":false,"unlisted":false,"editUrl":"https://github.com/eclipse-lmos/website/edit/source/docs/lmos_protocol/04-agent_description.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"Agent Description Format","description":"Standardized agent metadata format.","sidebar_position":3},"sidebar":"protocolSidebar","previous":{"title":"Digital Identities","permalink":"/lmos/docs/lmos_protocol/digital_identity"},"next":{"title":"Tool Description Format","permalink":"/lmos/docs/lmos_protocol/tool_description"}}');var s=t(4848),o=t(8453);const r={title:"Agent Description Format",description:"Standardized agent metadata format.",sidebar_position:3},a=void 0,l={},c=[{value:"Problem statement",id:"problem-statement",level:2},{value:"Solution",id:"solution",level:2},{value:"Agent Communication",id:"agent-communication",level:2}];function d(e){const n={a:"a",code:"code",h2:"h2",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h2,{id:"problem-statement",children:"Problem statement"}),"\n",(0,s.jsx)(n.p,{children:"A standardized format is essential for describing the capabilities and metadata of intelligent agents. This specification should offer an appropriate level of abstraction to ensure interoperability across a wide range of agent platforms and domains."}),"\n",(0,s.jsx)(n.p,{children:"Agent metadata is essential for several reasons:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Discovery:"})," It allows agents to find each other based on capabilities, making it easier to assemble multi-agent systems for complex tasks."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Interoperability:"})," By specifying input/output formats and API endpoints, metadata ensures that agents can communicate effectively."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Version information:"})," Version information aids in managing updates and ensuring compatibility between different agent versions."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Security:"})," Metadata about authentication and encryption capabilities helps maintain a secure multi-agent environment."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Autonomy:"})," With comprehensive metadata, agents can make informed decisions about which other agents to interact with, enhancing the system's autonomy."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"solution",children:"Solution"}),"\n",(0,s.jsx)(n.p,{children:"In the context of the LMOS protocol an agent is a specialized software program that uses the capabilities of a machine learning model to perform specific tasks. An agent typically has a clear goal or objective it aims to achieve, which is dependent on the task it's designed to perform. The goal drives how the agent interacts with data, models, or APIs to accomplish its task."}),"\n",(0,s.jsx)(n.p,{children:"LMOS agents can have a state (properties), can perform actions and emit events. State represents the agent\u2019s current configuration or context. Actions define the tasks the agent can perform. Events allow the agent to proactively notify users or other agents."}),"\n",(0,s.jsxs)(n.p,{children:["The LMOS Agent Description Format builds on top of the ",(0,s.jsx)(n.a,{href:"https://www.w3.org/TR/wot-thing-description11/",children:"Thing Description (TD)"})," format from the Web of Things (WoT) specification and extends it by specifying an additional schema tailored to the needs of intelligent  agents. This allows agents to express their capabilities and services in a consistent, machine-readable way. TDs are usually encoded in JSON format that supports JSON-LD."]}),"\n",(0,s.jsx)(n.p,{children:"A Thing Description typically contains:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Metadata about the Thing"}),"\n",(0,s.jsx)(n.li,{children:"A longer explanation of what the Thing does or represents."}),"\n",(0,s.jsx)(n.li,{children:"Interaction affordances (Properties, Actions, and Events)"}),"\n",(0,s.jsx)(n.li,{children:"Data JSON schemas for machine-understandability"}),"\n",(0,s.jsx)(n.li,{children:"Information about the version of the Thing"}),"\n",(0,s.jsx)(n.li,{children:"Security definitions"}),"\n",(0,s.jsx)(n.li,{children:"Web links to related Things or resources"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Interaction affordances define how you can interact with the Thing, which may include:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Properties:"})," The state or attributes of the Thing, which can be read."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Actions:"})," Functions that can be invoked on the Thing ."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Events:"})," Notifications emitted by the Thing when certain conditions are met."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["The TD allows mapping of these interactions to various transport protocols (HTTP, MQTT, CoAP, etc.). This makes it\npossible to abstract away the underlying technical details of the protocol. For more details see ",(0,s.jsx)(n.a,{href:"/docs/multi_agent_system/agent_communication",children:"Agent\nCommunication"}),"."]}),"\n",(0,s.jsx)(n.p,{children:'The format is structured similarly to the Thing Description but includes LMOS-specific properties to describe the agent\u2019s capabilities and metadata. These additional properties are defined within the "lmos" namespace, ensuring they are clearly differentiated from standard WoT terms.'}),"\n",(0,s.jsxs)(n.p,{children:["Here is the table and description for an ",(0,s.jsx)(n.strong,{children:"Agent"})," in the context of the ",(0,s.jsx)(n.strong,{children:"LMOS Protocol vocabulary"}),":"]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:(0,s.jsx)(n.strong,{children:"Vocabulary Term"})}),(0,s.jsx)(n.th,{children:(0,s.jsx)(n.strong,{children:"Value"})}),(0,s.jsx)(n.th,{children:(0,s.jsx)(n.strong,{children:"Assignment"})}),(0,s.jsx)(n.th,{children:(0,s.jsx)(n.strong,{children:"Type"})})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"@context"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.a,{href:"https://eclipse.dev/lmos/protocol/v1",children:"https://eclipse.dev/lmos/protocol/v1"})}),(0,s.jsx)(n.td,{children:"Mandatory"}),(0,s.jsx)(n.td,{children:"URI"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"@type"})}),(0,s.jsx)(n.td,{children:"Agent"}),(0,s.jsx)(n.td,{children:"Mandatory"}),(0,s.jsx)(n.td,{children:"string"})]})]})]}),"\n",(0,s.jsx)(n.p,{children:"Example:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'{\n   "@context": [\n      "https://www.w3.org/2022/wot/td/v1.1",\n      {\n         "lmos": "https://eclipse.dev/lmos/protocol/v1",\n      }\n   ],\n   "@type": "lmos:Agent",\n   "id": "urn:uuid:6f1d3a7a-1f97-4e6b-b45f-f3c2e1c84c77",\n   "title": "Agent Name",\n   "lmos:metadata": {\n        "lmos:vendor": {\n            "lmos:name": "Deutsche Telekom AG",\n            "lmos:url": "https://telekom.de"\n        }\n   }\n}\n'})}),"\n",(0,s.jsx)(n.p,{children:"Full example:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'{\n   "@context": [\n      "https://www.w3.org/2022/wot/td/v1.1",\n      {\n         "lmos": "https://eclipse.dev/lmos/protocol/v1",\n      }\n   ],\n   "id": "urn:uuid:6f1d3a7a-1f97-4e6b-b45f-f3c2e1c84c77",\n   "title": "WeatherAgent",\n   "@type": "lmos:Agent",\n   "links": [{\n      "rel": "service-doc",\n      "href": "https://weatherai.example.com/manual.pdf",\n      "type": "application/pdf",\n      "hreflang": "en"\n   }],\n   "lmos:metadata": {\n        "lmos:vendor": {\n            "lmos:name": "Deutsche Telekom AG",\n            "lmos:url": "https://telekom.de"\n        }\n   }\n    "securityDefinitions": {\n        "basic_sc": {\n            "scheme": "basic",\n            "in": "header"\n        }\n    },\n    "security": "basic_sc",\n    "properties": {\n        "modelConfiguration": {\n            "description": "Current configuration of the underlying LLM, including version, temperature, and maximum tokens.",\n            "type": "object",\n            "readOnly": true,\n            "properties": {\n                "modelName": {\n                    "type": "string",\n                    "description": "Name of the model in use, e.g., gpt-4o."\n                },\n                "temperature": {\n                    "type": "number",\n                    "description": "Temperature setting for controlling response randomness.",\n                    "minimum": 0,\n                    "maximum": 1\n                },\n                "maxTokens": {\n                    "type": "integer",\n                    "description": "Maximum number of tokens the model is allowed to generate."\n                }\n            },\n            "forms": [\n                {\n                    "op": "readproperty",\n                    "href": "https://weatherai.example.com/things/urn:uuid:6f1d3a7a-1f97-4e6b-b45f-f3c2e1c84c77/properties/modelConfiguration",\n                    "contentType": "application/json"\n                }\n            ]\n        }\n    },\n    "actions": {\n        "getWeather": {\n            "description": "Fetches weather information based on user input.",\n            "safe": true,\n            "idempotent": false,\n            "synchronous": true,\n            "input": {\n               "type": "object",\n                "properties": {\n                    "question": {\n                        "type": "string"\n                    },\n                    "interactionMode": {\n                        "type": "string",\n                        "enum": ["text", "voice"]\n                    }\n                },\n                "required": ["question","interactionMode"]\n            },\n            "output": {\n                "type": "string",\n                "description": "Natural language output providing weather information."\n            },            \n            "forms": [\n                {\n                    "op": "invokeaction",\n                    "href": "https://weatherai.example.com/things/urn:uuid:6f1d3a7a-1f97-4e6b-b45f-f3c2e1c84c77/actions/getWeather",\n                    "contentType": "application/json",\n                    "htv:methodName":"POST"\n                }\n            ]\n        }\n    },\n    "events": {\n        "userFeedbackReceived": {\n            "description": "Emitted when a user provides feedback on the service, with a rating from 1 to 5.",\n            "data": {\n                "type": "object",\n                "properties": {\n                    "rating": {\n                        "type": "integer",\n                        "description": "User rating, where 1 is the lowest and 5 is the highest.",\n                        "minimum": 1,\n                        "maximum": 5\n                    },\n                    "comment": {\n                        "type": "string",\n                        "description": "Optional user comment providing additional feedback."\n                    }\n                },\n                "required": ["rating"]\n            },\n            "forms": [\n                {\n                    "op": "subscribeevent",\n                    "href": "https://weatherai.example.com/things/urn:uuid:6f1d3a7a-1f97-4e6b-b45f-f3c2e1c84c77/events/userFeedbackReceived",\n                    "contentType": "application/json"\n                }\n            ]\n        }\n    }\n}\n'})}),"\n",(0,s.jsx)(n.h2,{id:"agent-communication",children:"Agent Communication"}),"\n",(0,s.jsx)(n.p,{children:"To ensure interaction between agents, the following communication patterns must be supported:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Request-Reply"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Agents must be able to send requests and receive a single response, providing the requested information or acknowledgment."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"One Request-Multiple Responses"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Agents must be able to handle requests that return multiple responses over time, accommodating ongoing updates or multiple pieces of information."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Event-Driven/Notifications"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Agents must support the ability to send notifications without expecting a reply, allowing for status updates."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Publish-Subscribe"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"A mechanism must be in place to allow agents to publish messages or events and for other agents to subscribe and receive those messages."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Request-Stream / Response-Stream"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Continuous or real-time data streams must be supported, allowing agents to receive voice streams and response with voice streams."}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>a});var i=t(6540);const s={},o=i.createContext(s);function r(e){const n=i.useContext(o);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),i.createElement(o.Provider,{value:n},e.children)}}}]);